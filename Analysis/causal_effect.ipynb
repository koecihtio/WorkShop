{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コロナ禍におけるBCPの因果効果を推定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 傾向スコアを算出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/koeci/Google ドライブ/MBA/ワークショップ/data/Analysis/analysis_data_three.csv'\n",
    "df = pd.read_csv(path, encoding='cp932')\n",
    "\n",
    "# 分析するアウトカムと、（BCPの傾向スコアを算出するための）説明変数、群別変数の定義\n",
    "X_col = [\n",
    "    'lag_yj_total_assets',\n",
    "    'lag_yj_operating_cash_flow', 'lag_yj_ros', 'lag_yj_cash_deposit_ratio',\n",
    "    'lag_yj_leverage', 'lag_yj_stock_price_growth',\n",
    "    'lag_yj_net_profit_growth', 'lag_yj_firm_age',\n",
    "    'lag_yj_fixed_assets_ratio', 'lag_yj_extraordinary_loss',\n",
    "    'lag_yj_foreign_stock_ratio', 'earthquake', 'lag_earthquake',\n",
    "    'turnover', 'lag_turnover', 'lag_turnover_cumsum', 'sensitivity_analysis',\n",
    "    'lag_sensitivity_analysis', 'lag_sensitivity_analysis_cumsum', 'covid_19',\n",
    "    'lag_covid_19'\n",
    "    ]\n",
    "X = df[X_col]\n",
    "Z = df['BCP'].astype('int').astype('category')\n",
    "\n",
    "# ロジスティック回帰を用いて傾向スコアを算出する\n",
    "model = LogisticRegression(random_state=1234)\n",
    "model.fit(X=X, y=Z)\n",
    "ps = pd.Series(model.predict_proba(X=X)[:, 1])\n",
    "ps.name = 'ps'\n",
    "\n",
    "# psをdfにmerge\n",
    "df = pd.concat([df, ps], axis=1)\n",
    "\n",
    "# 異常値処理\n",
    "\n",
    "# 2020~2021年に売上高成長率がマイナスになった企業に限定する\n",
    "df = df.query('year == 2021 and b_sales_growth < 0')\n",
    "q = 1\n",
    "q_min = q / 100\n",
    "q_max = 1 - q / 100\n",
    "df = df[(df['b_sales_growth'] >= df['b_sales_growth'].quantile(q_min)) & (df['b_sales_growth'] <= df['b_sales_growth'].quantile(q_max))]\n",
    "ps = df['ps']\n",
    "y = df['b_sales_growth']\n",
    "Z = df['BCP'].astype('int').astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 傾向スコアマッチング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATT = 0.028 ± 0.071 (s.d=0.036)\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "table = pd.concat([ps, Z, y], axis=1)\n",
    "table.reset_index(drop=True, inplace=True)\n",
    "interval = np.arange(0, 1.05, 0.05)\n",
    "match_list = []\n",
    "for i in range(0, len(interval) - 1):\n",
    "    temp0 = table[(table['BCP'] == 0) & (interval[i] < table['ps']) & (table['ps'] < interval[i + 1])]\n",
    "    temp1 = table[(table['BCP'] == 1) & (interval[i] < table['ps']) & (table['ps'] < interval[i + 1])]\n",
    "    if (len(temp0) > 0) & (len(temp1) > 0):\n",
    "        match_list.append(temp1['b_sales_growth'].mean() - temp0['b_sales_growth'].mean())\n",
    "\n",
    "print('ATT = {:.3f} ± {:.3f} (s.d={:.3f})'.format(np.nanmean(match_list), np.nanstd(match_list) * 1.96, np.std(match_list)))\n",
    "print(len(match_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATT = 0.0157 ± 0.0152 (s.d.=0.0059)\n"
     ]
    }
   ],
   "source": [
    "ATT_list = []\n",
    "sample_size = len(df[df['BCP'] == 1])\n",
    "\n",
    "for i in range(5000):\n",
    "    idx1 = pd.Series(df.loc[df['BCP'] == 1, 'b_sales_growth'].index).sample(n=sample_size, replace=True, random_state=i)\n",
    "    idx0 = pd.Series(df.loc[df['BCP'] == 0, 'b_sales_growth'].index).sample(n=sample_size, replace=True, random_state=i)\n",
    "    \n",
    "    Z_tmp = np.r_[Z[idx1], Z[idx0]]\n",
    "    y_tmp = np.r_[y[idx1], y[idx0]]\n",
    "    ps_tmp = np.r_[ps[idx1], ps[idx0]]\n",
    "    w01_tmp = (1 - Z_tmp) * ps_tmp / (1 - ps_tmp)\n",
    "\n",
    "    E1 = np.mean(y_tmp[Z_tmp == 1])\n",
    "    E0 = np.sum(y_tmp * w01_tmp) / np.sum(w01_tmp)\n",
    "    ATT = E1 - E0\n",
    "    ATT_list.append(ATT)\n",
    "\n",
    "print('ATT = {:.4f} ± {:.4f} (s.d.={:.4f})'.format(np.nanmean(ATT_list), np.nanstd(ATT_list)*2.58, np.nanstd(ATT_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017900860508287764\n"
     ]
    }
   ],
   "source": [
    "# DR推定量の取得を関数化\n",
    "def get_dr(df, y_column, x_columns, treat_column, dummy_columns=[]):\n",
    "    \"\"\"\n",
    "    DR推定量を算出する関数\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        目的変数、共変量、介入有無のフラグ、傾向スコアのカラムが入ったデータフレーム\n",
    "    y_column : str\n",
    "        目的変数のカラム名\n",
    "    x_columns : list\n",
    "        説明変数のカラム名が格納されているリスト\n",
    "    treat_column : str\n",
    "        介入有無のフラグがあるカラム名\n",
    "    dummy_columns : list\n",
    "        説明変数うち、ダミー変数にする必要のあるカラム名が格納されているリスト\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    result : int\n",
    "    \"\"\"\n",
    "    ## DR推定量の算出\n",
    "    n = len(df)\n",
    "    # 結果変数\n",
    "    y = df[y_column]\n",
    "    #共変量\n",
    "    X = pd.get_dummies(df[x_columns], columns=dummy_columns, drop_first=True)\n",
    "    # 介入効果\n",
    "    z = df[treat_column]\n",
    "    # 傾向スコアの算出\n",
    "    ps_model = LogisticRegression(random_state=1234).fit(X, z)\n",
    "    ps_score = ps_model.predict_proba(X)[:, 1]\n",
    "    # 介入群のみのデータ\n",
    "    group1_df = df[df[treat_column]==1]\n",
    "    y1 = group1_df[y_column]\n",
    "    X1 = pd.get_dummies(group1_df[x_columns], columns=dummy_columns, drop_first=True)\n",
    "    # 対照群のみのデータ\n",
    "    group0_df = df[df[treat_column]==0]\n",
    "    y0 = group0_df[y_column]\n",
    "    X0 = pd.get_dummies(group0_df[x_columns], columns=dummy_columns, drop_first=True)\n",
    "    # 介入群に対するモデル\n",
    "    model1 = sm.OLS(y1, X1).fit()\n",
    "    # 対照群に対するモデル\n",
    "    model0 = sm.OLS(y0, X0).fit()\n",
    "    # データ全体をpredictする\n",
    "    fitted1 = model1.predict(X)\n",
    "    fitted0 = model0.predict(X)\n",
    "    # 推定\n",
    "    dre1 = sum(z * y / ps_score + (1 - z  / ps_score)* fitted1) / n\n",
    "    dre0 = sum((1 - z) /(1 - ps_score) * y + (1 - (1 - z)  / (1 - ps_score))* fitted0) / n\n",
    "\n",
    "    result = dre1 - dre0\n",
    "    print(result)\n",
    "\n",
    "y_column = 'b_sales_growth'\n",
    "x_columns = X_col\n",
    "treat_column = 'BCP'\n",
    "get_dr(df, y_column, x_columns, treat_column)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "530756d384d84b166bf1cc6dadec8b1c5ff774bb470199997245af3e35454b18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
