{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XBRL元データ抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_original_xbrl(edinet_path, catcher_path):\n",
    "    \"\"\"EDIENTと有報キャッチャーのXBRLから統合データフレームを返す\n",
    "\n",
    "    Args:\n",
    "        edinet_path (str): EDINETから取得したXBRL解析後ファイルのパス\n",
    "        catcher_path (str): EDINETから取得したXBRL解析後ファイルのパス\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: XBRLデータフレーム\n",
    "    \"\"\"\n",
    "\n",
    "    # ファイル読込\n",
    "    with open(edinet_path, mode='rb') as file:\n",
    "        df_stk_1 = pickle.load(file)\n",
    "    with open(catcher_path, mode='rb') as file:\n",
    "        df_stk_2 = pickle.load(file)\n",
    "\n",
    "    # HTMLが存在する書類を返す\n",
    "    df_stk = pd.concat([df_stk_1, df_stk_2], axis=0)\n",
    "    df_stk = df_stk.query('not stk_html == 0')\n",
    "\n",
    "    return df_stk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注釈テーブルを整形する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_original_to_df(html):\n",
    "    \"\"\"1社について、注釈テーブルを作成する\n",
    "\n",
    "    Args:\n",
    "        html (str): 注釈文章が入ったHTML\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 注釈データフレーム\n",
    "    \"\"\"\n",
    "    # 注釈文章をpタグで分割したままのデータフレームを出力\n",
    "    soup  = BeautifulSoup(html, 'html.parser')\n",
    "    div_last = soup.findAll('div')[-1]\n",
    "    annotation = div_last.findNextSiblings() #<p>タグ（等）が個数分だけ入る\n",
    "    annot_list = [Translate(a.text).roundtonum().value.rstrip(' ').rstrip('　').replace('\\u3000', '').replace('\\xa0', '')\n",
    "        for a in annotation] # 丸数字の変換とUTF-8文字の削除\n",
    "    annot_list = [a for a in annot_list if a]\n",
    "    df = pd.DataFrame(annot_list).T\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_annotations(df_stk):\n",
    "    # 全企業について注釈テーブルを作成する\n",
    "    df_list = []\n",
    "    for code, name, ymd, html in zip(df_stk['edinet_code'], df_stk['firm_name'], df_stk['filling_ymd'], df_stk['stk_html']):\n",
    "        annotation_df = annotation_original_to_df(html)\n",
    "        firm_df = pd.concat([pd.DataFrame([code, name, ymd]).T, annotation_df], axis=1)\n",
    "        columns_len = len(firm_df.columns)\n",
    "        new_columns = [str(i) for i in range(columns_len)]\n",
    "        firm_df.set_axis(labels=new_columns, axis=1, inplace=True)\n",
    "        df_list.append(firm_df)\n",
    "\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edinet_path = 'C:/Users/koeci/Google ドライブ/MBA/ワークショップ/intermediate/tsutsumi_stockholders/xbrl_parsed_0924.pickle'\n",
    "catcher_path = 'C:/Users/koeci/Google ドライブ/MBA/ワークショップ/intermediate/tsutsumi_stockholders/xbrl_parsed_1015.pickle'\n",
    "df_stk = make_original_xbrl(edinet_path, catcher_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = merge_annotations(df_stk=df_stk)\n",
    "path = 'C:/Users/koeci/Google ドライブ/MBA/ワークショップ/output/tsutsumi_stockholders/OriginalAnnotation.csv'\n",
    "# annotations_df.to_csv(path, encoding='cp932', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注釈テーブルの最終版を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_annotation_comp(annotation):\n",
    "    df = annotation.copy()\n",
    "    for col in annotation.columns:\n",
    "        df[col] = df[col].apply(lambda x: x.lstrip().rstrip().replace('?', '') if x == x and x is not None else np.nan)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../output/tsutsumi_stockholders/Annotation.csv'\n",
    "annotation = pd.read_csv(path, encoding='cp932')\n",
    "annotation = make_annotation_comp(annotation)\n",
    "save_path = '../../output/tsutsumi_stockholders/Annotation_comp.csv'\n",
    "annotation.to_csv(save_path, encoding='cp932', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 株主テーブルの修正前テーブルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stockholders_origin(html):\n",
    "    \"\"\"修正前の株主テーブルを作成する\n",
    "\n",
    "    Args:\n",
    "        html (str): BeautifulSoupで解析するHTML\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: HTMLの表を読み込んだデータフレーム（複数ページにまたがる場合は結合する）\n",
    "    \"\"\"\n",
    "    df_list = pd.read_html(html, header=0)\n",
    "    if len(df_list) >= 2:\n",
    "        df = pd.concat(df_list)\n",
    "    else:\n",
    "        df = df_list[0]\n",
    "\n",
    "    # 列名を修正する\n",
    "    cols = df.columns\n",
    "    if len(cols) >= 1:\n",
    "        if cols[0] == 'Unnamed: 0':\n",
    "            new_cols = df.iloc[0, :]\n",
    "            df.drop(index=0, inplace=True)\n",
    "            df.set_axis(labels=new_cols, axis=1, inplace=True)\n",
    "\n",
    "    len_cols = len(df.columns)\n",
    "    new_cols = [i for i in range(3, 3 + len_cols)] # 左横に3つ（edinet_code, firm_name, filling_ymd）が入るので3から\n",
    "    df.set_axis(labels=new_cols, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stockholders_original(df_stk):\n",
    "    # 全企業について株主テーブルを作成する\n",
    "    df_list = []\n",
    "    for code, name, ymd, html in zip(df_stk['edinet_code'], df_stk['firm_name'], df_stk['filling_ymd'], df_stk['stk_html']):\n",
    "        stockholders = make_stockholders_origin(html) # 株主テーブルの作成\n",
    "        stockholders.insert(0, 'edinet_code', code)\n",
    "        stockholders.insert(1, 'firm_name', name)\n",
    "        stockholders.insert(2, 'filling_ymd', ymd)\n",
    "        columns_len = len(stockholders.columns)\n",
    "        new_columns = [str(i) for i in range(columns_len)]\n",
    "        stockholders.set_axis(labels=new_columns, axis=1, inplace=True) # concatする際に列名重複エラーが出るので、番号列名に変える\n",
    "        df_list.append(stockholders)\n",
    "\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "\n",
    "    # 作業用に注釈番号を分割した列を持っておく\n",
    "    stockholders_names = df.iloc[:, 3]\n",
    "    stockholders_names = stockholders_names.apply(lambda x: str(x).replace('注', '※')) # 注を※に変えて変換しやすくする\n",
    "\n",
    "    a_num_list = []\n",
    "    for s_name in stockholders_names:\n",
    "        name_split = str(s_name).split('※')\n",
    "        if len(name_split) >= 2:\n",
    "            a_num = name_split[1].replace('(', '').replace('（', '').replace(')', '').replace('）', '').replace('※', '')\n",
    "            a_num = Translate(a_num).roundtonum().zentohan().value.replace('、', ',').replace('.', ',') # 全角半角、囲い数字、\",\"の修正\n",
    "        else:\n",
    "            a_num = np.nan\n",
    "        a_num_list.append(a_num)\n",
    "\n",
    "    a_num_split_list = [str(a).split(',') for a in a_num_list]\n",
    "    a_num_df = pd.DataFrame(a_num_split_list)\n",
    "\n",
    "    # 株主テーブルに結合する\n",
    "    df.reset_index(inplace=True)\n",
    "    a_num_df.set_axis(labels=[str(i) for i in range(len(df.columns), len(df.columns) + len(a_num_df.columns))], axis=1, inplace=True)\n",
    "    df = pd.concat([df, a_num_df], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = save_stockholders_original(df_stk=df_stk)\n",
    "save_path = 'C:/Users/koeci/Google ドライブ/MBA/ワークショップ/output/tsutsumi_stockholders/stockholders_before_fix.xlsx'\n",
    "df.to_excel(save_path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手作業で注釈テーブル・株主テーブルを修正したあとの操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手作業で整形した株主テーブルをさらに整形する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_more_stockholders(stockholders):\n",
    "    \"\"\"手作業で整形した株主テーブルを分割処理等にかける\n",
    "\n",
    "    Args:\n",
    "        stockholders (pandas.DataFrame): 目視での処理済みデータフレーム\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 処理を施したデータフレーム\n",
    "    \"\"\"\n",
    "    df = stockholders.copy()\n",
    "\n",
    "    # stockとstock_rateの（）を分割する\n",
    "    for col in ['stock', 'stock_rates']:\n",
    "        fixed_values = df[col].apply(lambda x: Translate(str(x)).zentohan().value.replace('<', '(').replace('>', ')'))\n",
    "\n",
    "        main_value_list = []\n",
    "        sub_value_list = []\n",
    "        for value in fixed_values:\n",
    "            split_value = value.split('(')\n",
    "            if len(split_value) >= 2:\n",
    "                # 元の値\n",
    "                main_value = split_value[0]\n",
    "                main_value = main_value.replace('(', '').replace(' ', '').replace(',', '').replace('?', '').replace('%', '')\n",
    "                # ()内の値\n",
    "                sub_value = split_value[1]\n",
    "                sub_value = sub_value.replace(')', '').replace(' ', '').replace(',', '').replace('?', '').replace('%', '')\n",
    "            else:\n",
    "                main_value = value.replace('(', '').replace(' ', '').replace(',', '').replace('?', '').replace('%', '')\n",
    "                sub_value = np.nan\n",
    "\n",
    "            main_value_list.append(main_value)\n",
    "            sub_value_list.append(sub_value)\n",
    "        \n",
    "        main_colname = col + '_main'\n",
    "        sub_colname = col + '_sub'\n",
    "        df[main_colname] = main_value_list\n",
    "        df[sub_colname] = sub_value_list\n",
    "\n",
    "    # 注釈番号列を修正する\n",
    "    print(df.columns)\n",
    "    a_num_col = [c for c in df.columns if 'a_num_' in c]\n",
    "    for col in a_num_col:\n",
    "        df[col] = df[col].apply(lambda x: str(x).replace(' ', '').replace('　', ''))\n",
    "\n",
    "    # その他の行を修正する\n",
    "    for col in ['firm_name', 'loc']:\n",
    "        df[col] = df[col].apply(lambda x: x.replace('?', '') if x == x and x is not None else np.nan)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['edinet_code', 'firm_name', 'filling_ymd', 'stockholder', 'a_num_1',\n",
      "       'a_num_2', 'a_num_3', 'a_num_4', 'a_num_5', 'loc', 'stock',\n",
      "       'stock_rates', 'stock_main', 'stock_sub', 'stock_rates_main',\n",
      "       'stock_rates_sub'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# データ読込\n",
    "stockholder_path = '../../output/tsutsumi_stockholders/Stockholders.csv' # 株主テーブルの読込\n",
    "stockholders = pd.read_csv(stockholder_path, encoding='cp932', header=0)\n",
    "new_stockholders = fix_more_stockholders(stockholders=stockholders)\n",
    "new_stockholders.drop_duplicates(subset=['edinet_code', 'stockholder'], keep='first', inplace=True)\n",
    "save_path = '../../output/tsutsumi_stockholders/Stockholders_comp.csv'\n",
    "new_stockholders.to_csv(save_path, encoding='cp932', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 株主テーブルの最終チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = new_stockholders['stock_main'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最終アウトプットを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_output(nayose, security_table, annotation, stockholders):\n",
    "    # すべてを１つのテーブルに収める\n",
    "    df_comp = pd.merge(left=stockholders, right=nayose, on='edinet_code', how='left')\n",
    "    df_comp = pd.merge(left=df_comp, right=annotation, on='edinet_code', how='left')\n",
    "\n",
    "    # 注釈番号と注釈文章を対応させる\n",
    "    for i in range(len([c for c in df_comp.columns if 'a_num_' in c])): # 注釈番号の数だけfor分を回していく\n",
    "        value_list = []\n",
    "        colname = 'a_num_' + str(i + 1)\n",
    "        for edinet_code, a_num in zip(df_comp['edinet_code'], df_comp[colname]):\n",
    "            if type(a_num) == float and a_num == a_num and a_num is not None:\n",
    "                annotation_colname = 'a_' + str(int(a_num))\n",
    "                try:\n",
    "                    annot_text = annotation.loc[edinet_code, annotation_colname]\n",
    "                except:\n",
    "                    print(f'{edinet_code} was not matched')\n",
    "                    annot_text = None\n",
    "            else:\n",
    "                annot_text = None\n",
    "\n",
    "            value_list.append(annot_text) # 注釈文章を格納していく\n",
    "\n",
    "        new_colname = 'a_text_' + str(i + 1)\n",
    "        df_comp[new_colname] = value_list\n",
    "\n",
    "    # 証券コードの補完：証券コードNAとそれ以外で分割→補完→マージ\n",
    "    df_comp_nona = df_comp.copy()[df_comp['security_code'] == df_comp['security_code']]\n",
    "    df_comp_na = df_comp.copy()[~(df_comp['security_code'] == df_comp['security_code'])]\n",
    "    fixed_security_code = list(map(lambda x: security_table[x], df_comp_na['edinet_code']))\n",
    "    df_comp_na['security_code'] = fixed_security_code\n",
    "    df_comp = pd.concat([df_comp_nona, df_comp_na], axis=0)\n",
    "\n",
    "    # 各列の最終修正\n",
    "    df_comp['stock_sub'] = df_comp['stock_sub'].replace('-', '').replace('―', '')\n",
    "    df_comp['stock_rates_sub'] = df_comp['stock_rates_sub'].replace('-', '').replace('―', '')\n",
    "    for col in ['edinet_code', 'firm_name', 'filling_ymd', 'stockholder', 'loc', 'stock',\n",
    "    'stock_rates', 'a_text_1', 'a_text_2', 'a_text_3', 'a_text_4', 'a_text_5']:\n",
    "        df_comp[col] = df_comp[col].apply(lambda x: str(x).replace('?', ''))\n",
    "\n",
    "    # 作業用に注釈番号を分割した列を持っておく\n",
    "    stockholders_names = df_comp['stockholder'].apply(lambda x: str(x).replace('注', '※').replace('(', '※').replace('（', '※').replace('＊', '※'))\n",
    "    new_stockholders = []\n",
    "    for row in stockholders_names:\n",
    "        new_stockholders.append(row.split('※')[0])\n",
    "\n",
    "    df_comp['stockholder_rem'] = new_stockholders\n",
    "        \n",
    "    for i in range(len([c for c in df_comp.columns if 'a_text_' in c])):\n",
    "        col = 'a_text_' + str(i + 1)\n",
    "        df_comp[col] = df_comp[col].apply(lambda x: x.rstrip() if x == x and x is not None else np.nan)\n",
    "\n",
    "    df_comp['stock_main'] = df_comp['stock_main'].apply(lambda x: int(x))\n",
    "    df_comp['stock_rates_main'] = df_comp['stock_rates_main'].apply(lambda x: float(x))\n",
    "\n",
    "    return df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "nayose_path = '../../data/EDINET/code_list/edinet_security_code.csv'\n",
    "security_na_path = '../../intermediate/tsutsumi_stockholders/securities_na.csv'\n",
    "annotation_path = '../../output/tsutsumi_stockholders/Annotation_comp.csv'\n",
    "stockholder_path = '../../output/tsutsumi_stockholders/Stockholders_comp.csv'\n",
    "\n",
    "nayose = pd.read_csv(nayose_path, encoding='cp932', dtype={'security_code': str})\n",
    "security_na = pd.read_csv(security_na_path, encoding='cp932', header=0)\n",
    "security_table = {e: s for e, s in zip(security_na['edinet_code'], security_na['security_code'])}\n",
    "annotation = pd.read_csv(annotation_path, encoding='cp932')\n",
    "a_cols = ['edinet_code'] + [col for col in annotation.columns if 'a_' in col]\n",
    "annotation = annotation[a_cols]\n",
    "annotation.set_index(keys='edinet_code', inplace=True)\n",
    "stockholders = pd.read_csv(stockholder_path, encoding='cp932')\n",
    "\n",
    "output = make_output(nayose=nayose, security_table=security_table, annotation=annotation, stockholders=stockholders)\n",
    "output = output[[\n",
    "    'edinet_code', 'security_code', 'firm_name', 'filling_ymd', 'stockholder', 'stockholder_rem', 'loc', 'stock',\n",
    "    'stock_rates', 'stock_main', 'stock_sub', 'stock_rates_main',\n",
    "    'stock_rates_sub', 'a_num_1', 'a_num_2', 'a_num_3', 'a_num_4', 'a_num_5', 'a_text_1', 'a_text_2',\n",
    "    'a_text_3', 'a_text_4', 'a_text_5'\n",
    "]]\n",
    "\n",
    "save_path = '../../output/tsutsumi_stockholders/stockholders_data_v2.csv'\n",
    "output.to_csv(save_path, encoding='cp932', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28464\n",
      "28464\n",
      "Series([], Name: edinet_code, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "print(output.count()['edinet_code'])\n",
    "print(output.drop_duplicates(subset=['edinet_code', 'stockholder'])['edinet_code'].count())\n",
    "print(output[output.duplicated(subset=['edinet_code', 'stockholder']) == True]['edinet_code'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = output.groupby('edinet_code')['stock_rates_main'].sum()\n",
    "check = output['stock_main'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edinet_code          object\n",
       "security_code         int64\n",
       "firm_name            object\n",
       "filling_ymd          object\n",
       "stockholder          object\n",
       "loc                  object\n",
       "stock                object\n",
       "stock_rates          object\n",
       "stock_main            int32\n",
       "stock_sub           float64\n",
       "stock_rates_main    float64\n",
       "stock_rates_sub     float64\n",
       "a_num_1             float64\n",
       "a_num_2             float64\n",
       "a_num_3             float64\n",
       "a_num_4             float64\n",
       "a_num_5             float64\n",
       "a_text_1             object\n",
       "a_text_2             object\n",
       "a_text_3             object\n",
       "a_text_4             object\n",
       "a_text_5             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.read_csv('../../output/tsutsumi_stockholders/stockholders_data_v2.csv', encoding='cp932', dtype={'stock_main': 'int', 'stock_rates_main': 'float'})\n",
    "output.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = output.count()\n",
    "count.to_csv('../../output/tsutsumi_stockholders/sample_size.csv', encoding='cp932')\n",
    "count = annotation.count()\n",
    "count.to_csv('../../output/tsutsumi_stockholders/annotation_sample_size.csv', encoding='cp932')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修正クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translate:\n",
    "    ZENKAKU = ''.join(chr(0xff01 + i) for i in range(94)) # 全角文字\n",
    "    HANKAKU = ''.join(chr(0x21 + i) for i in range(94)) # 半角文字\n",
    "    ZENTOHAN = str.maketrans(ZENKAKU, HANKAKU) # 全角→半角\n",
    "    HANTOZEN = str.maketrans(HANKAKU, ZENKAKU) # 半角→全角\n",
    "    ROUNDNUM = ''.join(chr(0x2460 + i) for i in range(9)) # 丸文字\n",
    "    NUM = ''.join(str(i) for i in range(1, 10)) # 数字\n",
    "    ROUNDTONUM = str.maketrans(ROUNDNUM, NUM) # 丸文字→数字\n",
    "    ADHOC_DICT = {'注': '※', '*': '※'} # 手動で整形する文字\n",
    "    ADHOC_TRANS = str.maketrans(ADHOC_DICT) # 変換テーブル\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        \n",
    "\n",
    "    def zentohan(self, zentohan=True):\n",
    "        if zentohan is True:\n",
    "            self.value = self.value.translate(self.ZENTOHAN)\n",
    "            return self\n",
    "        elif zentohan is False:\n",
    "            self.value = self.value.translate(self.HANTOZEN)\n",
    "            return self\n",
    "        else:\n",
    "            print('変換失敗')\n",
    "            return None\n",
    "\n",
    "\n",
    "    def roundtonum(self):\n",
    "        self.value = self.value.translate(self.ROUNDTONUM)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def adhoc_trans(self):\n",
    "        self.value = self.value.translate(self.ADHOC_TRANS)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fix:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def fix_value(self):\n",
    "        value_split = self.value.splitlines()\n",
    "        value_join = ''.join(value_split)\n",
    "        translate = Translate(value_join)\n",
    "        value_fixed = translate.zentohan().roundtonum().adhoc_trans().value # Translateオブジェクトのvalue変数(str)を抽出\n",
    "        value_fixed = value_fixed.replace(' ', '').replace('　', '').replace('\\xa0', '').replace('\\u3000', '')\n",
    "        self.value = value_fixed\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def fix_annotation_pre(self):\n",
    "        pattern_pre = r'^[0-9]\\.|^[0-9]|^\\(※\\)|^※|^※[0-9]|^\\(※\\)[0-9]\\.|\\(※[0-9]\\)|^\\(|^\\)|、[0-9]'\n",
    "        repl = ''\n",
    "        annot_fixed = re.sub(pattern=pattern_pre, repl=repl, string=self.value, count=10)\n",
    "        self.value = annot_fixed\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def fix_annotation_suff(self):\n",
    "        pattern_suff = r'[0-9]$|[0-9]\\.$|、$|※[0-9]$'\n",
    "        repl = ''\n",
    "        annot_fixed = re.sub(pattern=pattern_suff, repl=repl, string=self.value, count=10)\n",
    "        self.value = annot_fixed\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def fix_annotation_adhoc(self, pattern, repl):\n",
    "        \"\"\"\n",
    "        指定した文字を指定した文字に置き換える関数\n",
    "        \"\"\"\n",
    "        annot_list = [re.sub(pattern=pattern, repl=repl, string=a) for a in self.value]\n",
    "        self.value = annot_list\n",
    "\n",
    "        return self        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "530756d384d84b166bf1cc6dadec8b1c5ff774bb470199997245af3e35454b18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
