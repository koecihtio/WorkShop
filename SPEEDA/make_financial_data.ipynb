{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 財務データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 企業データを年で縦に結合する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各年を接合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各年の結合\n",
    "common = '../../data/SPEEDA/CompanyList_1018/CompanyList_'\n",
    "cols = [\n",
    "    'stock_code', 'corporate_number', 'firm_name', 'fiscal_year', 'status', 'establishment', 'prefecture',\n",
    "    'ceo', 'accounting', 'sales', 'operating_profit', 'net_profit', 'total_assets', 'cash',\n",
    "    'fixed_assets', 'total_liabilities', 'current_liabilities', 'stockholders_equity', 'other_gains',\n",
    "    'operating_cash_flow', 'stock_price', 'extraordinary_loss', 'foreign_stock_ratio'\n",
    "    ]\n",
    "df_list = []\n",
    "for year in range(1998, 2021):\n",
    "    path = common + str(year) + '.xlsx'\n",
    "    df = pd.read_excel(path, sheet_name='企業リスト', skiprows=7, header=0)\n",
    "    df.dropna(subset=['企業名称'], how='any', inplace=True) # 空行等を削除する\n",
    "    df.set_axis(labels=cols, axis=1, inplace=True)\n",
    "    df_list.append(df)\n",
    "    # print(f'{year} was successfully closed')\n",
    "\n",
    "df = pd.concat(df_list, axis=0) # 縦に結合\n",
    "df = df.assign( # 列の更新・修正（新規追加含む）\n",
    "    year = df['fiscal_year'].apply(lambda x: str(x)[0:4]),\n",
    "    month = df['fiscal_year'].apply(lambda x: str(x)[5:7]),\n",
    "    establishment = df['establishment'].apply(lambda x: str(x)[0:4] if not x == '-' else np.nan),\n",
    "    ceo = df['ceo'].apply(lambda x: x if not x == '-' else np.nan), # unicode error回避\n",
    "    prefecture = df['prefecture'].apply(lambda x: x if not x == '-' else np.nan),\n",
    "    accounting_code = df['accounting'].astype('category').cat.codes.replace(-1, np.nan), # 会計基準コードの付与\n",
    "    fixed_assets = df['fixed_assets'].fillna(0),\n",
    "    stockholders_equity = df['stockholders_equity'].fillna(0),\n",
    "    other_gains = df['other_gains'].fillna(0),\n",
    "    operating_cash_flow = df['operating_cash_flow'].fillna(0),\n",
    "    extraordinary_loss = df['extraordinary_loss'].fillna(0),\n",
    ")\n",
    "\n",
    "# 業種の付与\n",
    "path = '../../data/TDnet/証券コードリスト/syoken_code.xls'\n",
    "ind_data = pd.read_excel(path, sheet_name='Sheet1', header=0)\n",
    "ind_data.columns = [\n",
    "    'ymd', 'stock_code', 'firm_name', 'market', 'indcode_small', 'indname_small', 'indcode_large',\n",
    "    'indname_large', 'scale_code', 'scale_category'\n",
    "    ]\n",
    "ind_data = ind_data[['stock_code', 'indcode_small', 'indname_small', 'indcode_large', 'indname_large']]\n",
    "ind_data['stock_code'] = ind_data['stock_code'].apply(str)\n",
    "for col in ['indcode_small', 'indname_small', 'indcode_large', 'indname_large']:\n",
    "    ind_data[col] = ind_data[col].apply(lambda x: x if not x == '-' else np.nan)\n",
    "df = pd.merge(left=df, right=ind_data, on='stock_code', how='left')\n",
    "\n",
    "\n",
    "# 都道府県コードの付与\n",
    "path = '../../data/Prefecture/prefecture_code.csv'\n",
    "prefecture_code = pd.read_csv(path, encoding='cp932', header=0)\n",
    "df = pd.merge(left=df, right=prefecture_code, on='prefecture', how='left')\n",
    "\n",
    "# 列名でソート\n",
    "cols_sort = [\n",
    "    'stock_code', 'firm_name', 'year', 'month', 'establishment', 'ceo', 'accounting', 'accounting_code', 'prefecture', 'prefecture_code',\n",
    "    'indcode_small', 'indname_small', 'indcode_large', 'indname_large', 'sales', 'operating_profit',\n",
    "    'net_profit', 'total_assets', 'cash', 'fixed_assets', 'total_liabilities', 'current_liabilities',\n",
    "    'stockholders_equity', 'other_gains', 'operating_cash_flow', 'stock_price', 'extraordinary_loss', 'foreign_stock_ratio'\n",
    "]\n",
    "df = df.loc[:, cols_sort]\n",
    "df.sort_values(['stock_code', 'year'], inplace=True)\n",
    "\n",
    "# 保存(unicode error回避のためignoreを設定する)\n",
    "path = '../../data/SPEEDA/CompanyList_1018/CompanyListBinded.csv'\n",
    "with open(path, mode='w', encoding='cp932', errors='ignore') as file:\n",
    "    df.to_csv(file, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1期前のデータを横にくっつける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/SPEEDA/CompanyList_1018/CompanyListBinded.csv'\n",
    "df_pre = pd.read_csv(path, encoding='cp932', header=0)\n",
    "df_grouped = df_pre.groupby('stock_code')\n",
    "cols_pre = [\n",
    "    'year', 'month', 'establishment', 'ceo', 'accounting', 'accounting_code', 'prefecture', 'prefecture_code',\n",
    "    'sales', 'operating_profit', 'net_profit', 'total_assets', 'cash', 'fixed_assets', 'total_liabilities',\n",
    "    'current_liabilities', 'stockholders_equity', 'other_gains', 'operating_cash_flow', 'stock_price',\n",
    "    'extraordinary_loss', 'foreign_stock_ratio'\n",
    "]\n",
    "for col in cols_pre:\n",
    "    new_col = 'lag_' + col\n",
    "    df_pre[new_col] = df_grouped[col].shift(1)\n",
    "\n",
    "path = '../../data/SPEEDA/CompanyList_1018/CompanyListBinded_withPre.csv'\n",
    "df_pre.to_csv(path, encoding='cp932', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 経営指標を作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指標の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "path = '../../data/SPEEDA/CompanyList_1018/CompanyListBinded_withPre.csv'\n",
    "df = pd.read_csv(path, header=0, encoding='cp932')\n",
    "\n",
    "# 指標作成に当たり、割り算の分母が０になるのを未然に防ぐ\n",
    "cols = ['sales', 'operating_profit', 'stockholders_equity', 'other_gains', 'lag_stock_price', 'lag_net_profit']\n",
    "for col in cols:\n",
    "    df[col] = df[col].apply(lambda x: x if not x == 0 else np.nan)\n",
    "\n",
    "# 指標の作成\n",
    "df_b = df.assign(\n",
    "    b_sales_growth = (df['sales'] - df['lag_sales']) / df['lag_sales'],\n",
    "    b_total_assets = df['total_assets'],\n",
    "    b_operating_cash_flow = df['operating_cash_flow'],\n",
    "    b_ros = df['operating_profit'] / df['sales'],\n",
    "    b_cash_deposit_ratio = df['cash'] / (df['stockholders_equity'] + df['other_gains']),\n",
    "    b_leverage = df['total_assets'] / (df['stockholders_equity'] + df['other_gains']),\n",
    "    b_stock_price_growth = (df['stock_price'] - df['lag_stock_price']) / df['lag_stock_price'],\n",
    "    b_net_profit_growth = (df['net_profit'] - df['lag_net_profit']) / df['lag_net_profit'],\n",
    "    b_firm_age = df['year'] - df['establishment'],\n",
    "    b_fixed_assets_ratio = df['fixed_assets'] / (df['stockholders_equity'] + df['other_gains']),\n",
    "    b_extraordinary_loss = df['extraordinary_loss'],\n",
    "    b_foreign_stock_ratio = df['foreign_stock_ratio'],\n",
    "    b_earthquake_dummy = [1 if (y >= 2012) |((y == 2011) & (m >= 4)) else 0 for y, m in zip(df['year'], df['month'])],\n",
    "    b_turnover = [1 if not ceo == lag_ceo else 0 for ceo, lag_ceo in zip(df['ceo'], df['lag_ceo'])]\n",
    ")\n",
    "\n",
    "# 経営者交代の計測に前期分を使うので、前期がない行を落とす\n",
    "df_b.dropna(subset=['lag_ceo'], inplace=True)\n",
    "\n",
    "# 経営者交代回数の計測\n",
    "df_b_grouped = df_b.groupby('stock_code')\n",
    "df_turnover_count = df_b_grouped['b_turnover'].sum()\n",
    "df_turnover_count.name = 'b_turnover_count'\n",
    "df_b = pd.merge(left=df_b, right=df_turnover_count, on='stock_code', how='left')\n",
    "\n",
    "# 計算できなかった指標をNAにする\n",
    "df_b['b_firm_age'] = df_b['b_firm_age'].apply(lambda x: x if x >= 0 else np.nan)\n",
    "# df_b['b_net_profit_ratio'] = df_b['b_net_profit_ratio'].apply(lambda x: x if not np.isinf(x) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAなどの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2727\n"
     ]
    }
   ],
   "source": [
    "# NaNは全て落とす\n",
    "df_b.dropna(how='any', inplace=True)\n",
    "\n",
    "# 異常値処理\n",
    "def remove_outliers(df, col, q_min=0, q_max=1):\n",
    "    lower = df[col].quantile(q_min)\n",
    "    upper = df[col].quantile(q_max)\n",
    "    df = df.query(f'{lower} <= {col} & {col} <= {upper}')\n",
    "\n",
    "    return df\n",
    "\n",
    "cols = ['b_operating_cash_flow', 'b_ros', 'b_net_profit_growth', 'b_fixed_assets_ratio']\n",
    "for col in cols:\n",
    "    df_b = remove_outliers(df_b, col, q_min=0.005, q_max=0.995)\n",
    "    \n",
    "# 1期前の指標を横にくっつける\n",
    "cols = [c for c in df_b.columns if c.startswith('b_')]\n",
    "df_grouped = df_b.groupby('stock_code')\n",
    "for col in cols:\n",
    "    new_col = 'lag_' + col\n",
    "    df_b[new_col] = df_grouped[col].shift(1)\n",
    "\n",
    "df_b.dropna(how='any', inplace=True)\n",
    "\n",
    "# 年数が足りない企業＆年が飛んでいる企業を落とす\n",
    "df_grouped = df_b.groupby('stock_code').agg(['count', 'min']) # 企業ごとのレコード数をカウント\n",
    "df_grouped = df_grouped['year'] # year列を抽出（これをしないとエラー）\n",
    "df_b = pd.merge(left=df_b, right=df_grouped, how='left', on='stock_code') # 元データにカウント数をマージする\n",
    "df_b['row'] = df_b.groupby('stock_code').cumcount() # グループごとに連番を振る\n",
    "df_b['correct_year'] = df_b['min'] + df_b['row'] # 本来あるべき年\n",
    "df_b = df_b.query('year == correct_year') # 年が飛んでいる企業を落とす\n",
    "df_b = df_b.query('count >= 5') # 年数が足りない企業を落とす\n",
    "\n",
    "print(df_b['stock_code'].drop_duplicates().count()) # 企業数（ユニーク）の表\n",
    "\n",
    "# 保存\n",
    "path = '../../data/SPEEDA/CompanyList_1018/CompanyListProcessed.csv'\n",
    "df_b.to_csv(path, header=True, index=False, encoding='cp932')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yeo-Johnson変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b_sales_growth', 'b_total_assets', 'b_operating_cash_flow', 'b_ros', 'b_cash_deposit_ratio', 'b_leverage', 'b_stock_price_growth', 'b_net_profit_growth', 'b_firm_age', 'b_fixed_assets_ratio', 'b_extraordinary_loss', 'b_foreign_stock_ratio', 'lag_b_sales_growth', 'lag_b_total_assets', 'lag_b_operating_cash_flow', 'lag_b_ros', 'lag_b_cash_deposit_ratio', 'lag_b_leverage', 'lag_b_stock_price_growth', 'lag_b_net_profit_growth', 'lag_b_firm_age', 'lag_b_fixed_assets_ratio', 'lag_b_extraordinary_loss', 'lag_b_foreign_stock_ratio']\n"
     ]
    }
   ],
   "source": [
    "def trans_yeo_johnson(series):\n",
    "    mm = MinMaxScaler()\n",
    "    pt = PowerTransformer(standardize=True)\n",
    "    data = series.values.reshape(-1, 1)\n",
    "    mm.fit(data)\n",
    "    pt.fit(data)\n",
    "    result = pt.transform(data)\n",
    "\n",
    "    return result\n",
    "\n",
    "cols = [c for c in df_b.columns if ('b_' in c)]\n",
    "print(cols)\n",
    "for col in cols:\n",
    "    new_col = col.replace('b_', 'yj_')\n",
    "    df_b[new_col] = trans_yeo_johnson(df_b[col])\n",
    "\n",
    "df_b.rename(\n",
    "    columns={'b_earthquake_dummy': 'earthquake_dummy',\n",
    "    'lag_b_earthquake_dummy': 'lag_earthquake_dummy'}, inplace=True\n",
    "    )\n",
    "cols = [\n",
    "    'stock_code', 'firm_name', 'year', 'month', 'establishment', 'prefecture', 'prefecture_code',\n",
    "    'ceo', 'accounting', 'accounting_code',\n",
    "    'indcode_small', 'indname_small', 'indcode_large', 'indname_large'\n",
    "    ]\n",
    "cols = cols + [c for c in df_b.columns if ('yj_' in c) & ~('earthquake' in c)] + ['earthquake_dummy', 'lag_earthquake_dummy']\n",
    "df_yj = df_b[cols]\n",
    "\n",
    "path = '../../data/SPEEDA/CompanyList_1018/CompanyListYJ.csv'\n",
    "df_yj.to_csv(path, header=True, index=False, encoding='cp932')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "530756d384d84b166bf1cc6dadec8b1c5ff774bb470199997245af3e35454b18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
