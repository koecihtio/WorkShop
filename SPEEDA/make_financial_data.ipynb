{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 財務データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 企業データを年で縦に結合する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各年を接合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各年の結合\n",
    "common = '../../data/SPEEDA/CompanyList/CompanyList_'\n",
    "cols = [\n",
    "    'stock_code', 'corporate_number', 'firm_name', 'fiscal_year', 'status', 'establishment', 'prefecture',\n",
    "    'sales', 'operating_profit', 'net_profit', 'total_assets', 'cash', 'fixed_assets', 'total_liabilities',\n",
    "    'current_liabilities', 'stockholders_equity', 'other_gains', 'operating_cash_flow', 'stock_price'\n",
    "    ]\n",
    "df_list = []\n",
    "for year in range(1998, 2021):\n",
    "    path = common + str(year) + '.xlsx'\n",
    "    df = pd.read_excel(path, sheet_name='企業リスト', skiprows=7, header=0)\n",
    "    df.drop(index=[0, 1, 4233, 4234, 4235, 4236, 4237], inplace=True)\n",
    "    df.set_axis(labels=cols, axis=1, inplace=True)\n",
    "    df = df.assign(\n",
    "        year = df['fiscal_year'].apply(lambda x: str(x)[0:4]),\n",
    "        month = df['fiscal_year'].apply(lambda x: str(x)[5:7]),\n",
    "        establishment = df['establishment'].apply(lambda x: str(x)[0:4] if not x == '-' else np.nan),\n",
    "        prefecture = df['prefecture'].apply(lambda x: x if not x == '-' else np.nan)\n",
    "    )\n",
    "    df_list.append(df)\n",
    "    # print(f'{year} was successfully closed')\n",
    "\n",
    "df = pd.concat(df_list, axis=0)\n",
    "\n",
    "\n",
    "# 業種の付与\n",
    "path = '../../data/TDnet/証券コードリスト/syoken_code.xls'\n",
    "ind_data = pd.read_excel(path, sheet_name='Sheet1', header=0)\n",
    "ind_data.columns = [\n",
    "    'ymd', 'stock_code', 'firm_name', 'market', 'indcode_small', 'indname_small', 'indcode_large',\n",
    "    'indname_large', 'scale_code', 'scale_category'\n",
    "    ]\n",
    "ind_data = ind_data[['stock_code', 'indcode_small', 'indname_small', 'indcode_large', 'indname_large']]\n",
    "ind_data['stock_code'] = ind_data['stock_code'].apply(str)\n",
    "for col in ['indcode_small', 'indname_small', 'indcode_large', 'indname_large']:\n",
    "    ind_data[col] = ind_data[col].apply(lambda x: x if not x == '-' else np.nan)\n",
    "df = pd.merge(left=df, right=ind_data, on='stock_code', how='left')\n",
    "\n",
    "\n",
    "# 都道府県コードの付与\n",
    "path = '../../data/Prefecture/prefecture_code.csv'\n",
    "prefecture_code = pd.read_csv(path, encoding='cp932', header=0)\n",
    "df = pd.merge(left=df, right=prefecture_code, on='prefecture', how='left')\n",
    "\n",
    "cols_sort = [\n",
    "    'stock_code', 'firm_name', 'year', 'month', 'establishment', 'prefecture', 'prefecture_code',\n",
    "    'indcode_small', 'indname_small', 'indcode_large', 'indname_large', 'sales', 'operating_profit',\n",
    "    'net_profit', 'total_assets', 'cash', 'fixed_assets', 'total_liabilities', 'current_liabilities',\n",
    "    'stockholders_equity', 'other_gains', 'operating_cash_flow', 'stock_price'\n",
    "]\n",
    "\n",
    "df = df.loc[:, cols_sort]\n",
    "df.sort_values(['stock_code', 'year'], inplace=True)\n",
    "\n",
    "path = '../../data/SPEEDA/CompanyList/CompanyListBinded.csv'\n",
    "df.to_csv(path, encoding='cp932', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1期前のデータを横にくっつける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/SPEEDA/CompanyList/CompanyListBinded.csv'\n",
    "df_pre = pd.read_csv(path, encoding='cp932', header=0)\n",
    "df_grouped = df_pre.groupby('stock_code')\n",
    "cols_pre = [\n",
    "    'year', 'month', 'establishment', 'prefecture', 'prefecture_code',\n",
    "    'sales', 'operating_profit', 'net_profit', 'total_assets', 'cash', 'fixed_assets', 'total_liabilities',\n",
    "    'current_liabilities', 'stockholders_equity', 'other_gains', 'operating_cash_flow', 'stock_price'\n",
    "]\n",
    "\n",
    "for col in cols_pre:\n",
    "    new_col = 'lag_' + col\n",
    "    df_pre[new_col] = df_grouped[col].shift(1)\n",
    "\n",
    "path = '../../data/SPEEDA/CompanyList/CompanyListBinded_withPre.csv'\n",
    "df_pre.to_csv(path, encoding='cp932', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 経営指標を作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指標の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "path = '../../data/SPEEDA/CompanyList/CompanyListBinded_withPre.csv'\n",
    "df = pd.read_csv(path, header=0, encoding='cp932')\n",
    "\n",
    "# 指標作成に当たり、割り算の分母が０になるのを未然に防ぐ\n",
    "cols = ['sales', 'operating_profit', 'stockholders_equity', 'other_gains', 'lag_stock_price', 'lag_net_profit']\n",
    "for col in cols:\n",
    "    df[col] = df[col].apply(lambda x: x if not x == 0 else np.nan)\n",
    "\n",
    "# 指標の作成\n",
    "df_b = df.assign(\n",
    "    b_sales_growth = (df['sales'] - df['lag_sales']) / df['lag_sales'],\n",
    "    b_total_assets = df['total_assets'],\n",
    "    b_operating_cash_flow = df['operating_cash_flow'],\n",
    "    b_ros = df['operating_profit'] / df['sales'],\n",
    "    b_cash_deposit_ratio = df['cash'] / (df['stockholders_equity'] + df['other_gains']),\n",
    "    b_leverage = df['total_assets'] / (df['stockholders_equity'] + df['other_gains']),\n",
    "    b_stock_price_growth = (df['stock_price'] - df['lag_stock_price']) / df['lag_stock_price'],\n",
    "    b_net_profit_growth = (df['net_profit'] - df['lag_net_profit']) / df['lag_net_profit'],\n",
    "    b_firm_age = df['year'] - df['establishment'],\n",
    "    b_fixed_assets_ratio = df['fixed_assets'] / (df['stockholders_equity'] + df['other_gains']),\n",
    "    b_earthquake_dummy = [1 if (y >= 2012) |((y == 2011) & (m >= 4)) else 0 for y, m in zip(df['year'], df['month'])]\n",
    ")\n",
    "\n",
    "# 計算できなかった指標をNAにする\n",
    "df_b['b_firm_age'] = df_b['b_firm_age'].apply(lambda x: x if x >= 0 else np.nan)\n",
    "# df_b['b_net_profit_ratio'] = df_b['b_net_profit_ratio'].apply(lambda x: x if not np.isinf(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAなどの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2706\n"
     ]
    }
   ],
   "source": [
    "# NaNは全て落とす\n",
    "df_b.dropna(how='any', inplace=True)\n",
    "\n",
    "# 異常値処理\n",
    "def remove_outliers(df, col, q_min=0, q_max=1):\n",
    "    lower = df[col].quantile(q_min)\n",
    "    upper = df[col].quantile(q_max)\n",
    "    df = df.query(f'{lower} <= {col} & {col} <= {upper}')\n",
    "\n",
    "    return df\n",
    "\n",
    "cols = ['b_operating_cash_flow', 'b_ros', 'b_net_profit_growth', 'b_fixed_assets_ratio']\n",
    "for col in cols:\n",
    "    df_b = remove_outliers(df_b, col, q_min=0.005, q_max=0.995)\n",
    "    \n",
    "# 1期前の指標を横にくっつける\n",
    "cols = [c for c in df_b.columns if c.startswith('b_')]\n",
    "df_grouped = df_b.groupby('stock_code')\n",
    "for col in cols:\n",
    "    new_col = 'lag_' + col\n",
    "    df_b[new_col] = df_grouped[col].shift(1)\n",
    "\n",
    "df_b.dropna(how='any', inplace=True)\n",
    "\n",
    "# 年数が足りない企業＆年が飛んでいる企業を落とす\n",
    "df_grouped = df_b.groupby('stock_code').agg(['count', 'min']) # 企業ごとのレコード数をカウント\n",
    "df_grouped = df_grouped['year'] # year列を抽出（これをしないとエラー）\n",
    "df_b = pd.merge(left=df_b, right=df_grouped, how='left', on='stock_code') # 元データにカウント数をマージする\n",
    "df_b['row'] = df_b.groupby('stock_code').cumcount() # グループごとに連番を振る\n",
    "df_b['correct_year'] = df_b['min'] + df_b['row'] # 本来あるべき年\n",
    "df_b = df_b.query('year == correct_year') # 年が飛んでいる企業を落とす\n",
    "df_b = df_b.query('count >= 5') # 年数が足りない企業を落とす\n",
    "\n",
    "print(df_b['stock_code'].drop_duplicates().count()) # 企業数（ユニーク）の表\n",
    "\n",
    "# 保存\n",
    "path = '../../data/SPEEDA/CompanyList/CompanyListProcessed.csv'\n",
    "df_b.to_csv(path, header=True, index=False, encoding='cp932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yeo-Johnson変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b_sales_growth', 'b_total_assets', 'b_operating_cash_flow', 'b_ros', 'b_cash_deposit_ratio', 'b_leverage', 'b_stock_price_growth', 'b_net_profit_growth', 'b_firm_age', 'b_fixed_assets_ratio', 'b_earthquake_dummy', 'lag_b_sales_growth', 'lag_b_total_assets', 'lag_b_operating_cash_flow', 'lag_b_ros', 'lag_b_cash_deposit_ratio', 'lag_b_leverage', 'lag_b_stock_price_growth', 'lag_b_net_profit_growth', 'lag_b_firm_age', 'lag_b_fixed_assets_ratio', 'lag_b_earthquake_dummy']\n",
      "Index(['stock_code', 'firm_name', 'year', 'month', 'establishment',\n",
      "       'prefecture', 'prefecture_code', 'indcode_small', 'indname_small',\n",
      "       'indcode_large', 'indname_large', 'yj_sales_growth', 'yj_total_assets',\n",
      "       'yj_operating_cash_flow', 'yj_ros', 'yj_cash_deposit_ratio',\n",
      "       'yj_leverage', 'yj_stock_price_growth', 'yj_net_profit_growth',\n",
      "       'yj_firm_age', 'yj_fixed_assets_ratio', 'lag_yj_sales_growth',\n",
      "       'lag_yj_total_assets', 'lag_yj_operating_cash_flow', 'lag_yj_ros',\n",
      "       'lag_yj_cash_deposit_ratio', 'lag_yj_leverage',\n",
      "       'lag_yj_stock_price_growth', 'lag_yj_net_profit_growth',\n",
      "       'lag_yj_firm_age', 'lag_yj_fixed_assets_ratio', 'earthquake_dummy',\n",
      "       'lag_earthquake_dummy'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def trans_yeo_johnson(series):\n",
    "    mm = MinMaxScaler()\n",
    "    pt = PowerTransformer(standardize=True)\n",
    "    data = series.values.reshape(-1, 1)\n",
    "    mm.fit(data)\n",
    "    pt.fit(data)\n",
    "    result = pt.transform(data)\n",
    "\n",
    "    return result\n",
    "\n",
    "cols = [c for c in df_b.columns if ('b_' in c)]\n",
    "print(cols)\n",
    "for col in cols:\n",
    "    new_col = col.replace('b_', 'yj_')\n",
    "    df_b[new_col] = trans_yeo_johnson(df_b[col])\n",
    "\n",
    "df_b.rename(\n",
    "    columns={'b_earthquake_dummy': 'earthquake_dummy',\n",
    "    'lag_b_earthquake_dummy': 'lag_earthquake_dummy'}, inplace=True\n",
    "    )\n",
    "cols = [\n",
    "    'stock_code', 'firm_name', 'year', 'month', 'establishment', 'prefecture', 'prefecture_code',\n",
    "    'indcode_small', 'indname_small', 'indcode_large', 'indname_large'\n",
    "    ]\n",
    "cols = cols + [c for c in df_b.columns if ('yj_' in c) & ~('earthquake' in c)] + ['earthquake_dummy', 'lag_earthquake_dummy']\n",
    "df_yj = df_b[cols]\n",
    "\n",
    "path = '../../data/SPEEDA/CompanyList/CompanyListYJ.csv'\n",
    "df_yj.to_csv(path, header=True, index=False, encoding='cp932')\n",
    "print(df_yj.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.columns"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "530756d384d84b166bf1cc6dadec8b1c5ff774bb470199997245af3e35454b18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
